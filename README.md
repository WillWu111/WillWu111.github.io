# 吴云峰的简历

**中国江苏省苏州市**
邮箱: [yunfeng.wu22@gmail.com](mailto:yunfeng.wu22@gmail.com)
电话: +86 180-7174-9613
GitHub: [WillWu111](https://github.com/WillWu111)

---

## 教育背景

**西交利物浦大学** (2022年9月 – 2025年6月)
**信息与计算科学学士** | GPA: 3.92/4.0 (排名2/289)

- 核心课程: 算法与数据结构, 人工智能, 计算理论与导论, 数据库, 计算机网络
- 荣誉: 大学学术成就奖, 2023-2024

---

## 学术论文

1. Y. Wu, Q. Gao, Y. Liu, J. Sun, Z. Li, Y. Jin, Y. Yue, and X. Zhu, “Mitpose: Multi-Granularity Guided Vision Transformer for Human Pose Estimation,” accepted by Indin, 2025.
2. J. Sun, Z. Li, Q. Gao, Y. Wu, Y. Liu, Y. Jin, Y. Yue, and X. Zhu, “NUGaussRoom: Indoor Scene Reconstruction by 3D Gaussian Splatting Guided by Neural UDF and Geometry Aware Regularization,” under review, 2025.
3. B. You, J. Qin, Y. Xu, Y. Wu, Y. Liu, and S. Pan, “Multi-Modal Deep Learning Model for Stock Crises,” Proc. 2023 2nd Int. Conf. Front. Commun., DOI: 10.1109/CISDS61173.2023.00017, 2023.
4. B. You, J. Qin, Y. Xu, Y. Liu, Y. Wu, and S. Pan, “Multi-Modal Lightweight Deep Learning Model for Typhoon Prediction,” Proc. 2023 Int. Conf. Electron. Comput., DOI: 10.1145/3637494.3637514, 2023.

---

## 科研经历

### MITPose: 基于多粒度特征的人体姿态估计系统

- **核心创新**: 提出了多粒度特征提取框架，融合局部细节和全局语义信息，提升人体关键点定位精度。
- **技术突破**: 结合挤压-激励机制和深度过参数化卷积，自适应提取细粒度特征。
- **实验成果**: 在 COCO 数据集上达到 76.5 AP，在 MPII 数据集上达到 92.5 PCKh@0.5，超越现有 SOTA 方法。

### 智能水果采摘机器人系统

- **视觉算法**: 使用 SLAM 进行三维建图与定位，搭载 d435 相机，基于 YOLOv11 模型实现目标检测。
- **系统集成**: 通过手眼标定实现视觉系统与机械臂的深度集成，开发基于 ROS 的运动规划模块。
- **端到端优化**: 使用大语言模型优化采摘指令，在复杂环境中将采摘成功率提升至 85%。

### MMamba: 基于状态空间模型的目标检测框架

- **理论创新**: 首次将状态空间模型应用于目标检测任务，通过深度可分离卷积增强模型空间感知能力。
- **架构优化**: 设计双向特征融合机制，结合通道注意力实现多尺度目标的精确定位。
- **性能评估**: 在 CrowdHuman 数据集上取得 91.2 mAP，超越现有 SOTA 方法。

### NUGaussRoom: 基于 3D 高斯溅射与 UDF 引导的室内场景重建系统

- **相互学习机制**: 结合 3D 高斯溅射与未签名距离场（UDF）进行双向优化，相互约束提升重建精度与新视角合成质量。
- **几何约束优化**: 引入深度与法线等几何信息对高斯原语进行精细化约束，增强模型对细节形状的表达能力。
- **性能表现**: 在 ScanNet 与 ScanNet++ 数据集上取得领先性能，重建质量与视角合成能力超越现有方法。

### 基于脉冲神经网络的高效场景理解

- **算法创新**: 设计基于时序编码的脉冲神经网络，结合残差连接和时空注意力机制，提升特征提取能力。
- **能效优化**: 通过混合精度训练与稀疏函数激活，将模型能耗降低 75%，在 SUN-RGBD 数据集上保持 92% 分类准确率。

### Goo-ResNet: 高效图像分类网络设计

- **架构设计**: 提出了新型并行残差网络结构，通过多分支特征提取和自适应特征融合，实现轻量化与高性能的平衡。
- **实验验证**: 在 CIFAR-100 数据集上达到 84.5% 准确率，模型参数量仅为 ResNet-50 的 90%。

---

## 技术技能

- **计算机视觉**: 精通目标检测（YOLO, Faster R-CNN）、姿态估计（OpenPose, HRNet）、语义分割（UNet）；熟悉 ResNet, VIT, Swin, VMamba 及注意力机制（Self-Attention, Cross-Attnetion）。
- **深度学习框架**: 精通 PyTorch，熟练使用 MMCV（MMDetection, MMPose）。
- **开发技能**: Python, C++, CUDA, Linux/Shell, ROS。

---

## 联系方式

- **邮箱**: [yunfeng.wu22@gmail.com](mailto:yunfeng.wu22@gmail.com)
- **电话**: +86 180-7174-9613
- **GitHub**: [WillWu111](https://github.com/WillWu111)
